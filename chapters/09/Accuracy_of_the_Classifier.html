<!doctype html>
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>9.5 Accuracy of the classifier - Data Science for Everyone</title>
<meta name="description" content="You can download the file fromwine.csv.">



<meta property="og:type" content="article">
<meta property="og:locale" content="en_UK">
<meta property="og:site_name" content="Data Science for Everyone">
<meta property="og:title" content="9.5 Accuracy of the classifier">
<meta property="og:url" content="https://matthew-brett.github.io/dsfe/chapters/09/Accuracy_of_the_Classifier">


  <meta property="og:description" content="You can download the file fromwine.csv.">







  <meta property="article:published_time" content="2019-03-29T11:02:40+00:00">





  

  


<link rel="canonical" href="https://matthew-brett.github.io/dsfe/chapters/09/Accuracy_of_the_Classifier">







  <script type="application/ld+json">
    {
      "@context": "http://schema.org",
      "@type": "Person",
      "name": "Matthew Brett",
      "url": "https://matthew-brett.github.io/dsfe",
      "sameAs": null
    }
  </script>







<!-- end _includes/seo.html -->


<link href="/dsfe/feed.xml" type="application/atom+xml" rel="alternate" title="Data Science for Everyone Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/dsfe/assets/css/main.css">

<!--[if lte IE 9]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->


    <!-- start custom head snippets -->


<!-- end custom head snippets -->

    <link rel="stylesheet" href="/dsfe/assets/css/notebook-markdown.css">
    <link rel="stylesheet" href="/dsfe/assets/css/custom.css">
    <link rel="shortcut icon" type="image/png" href="/dsfe/favicon.png">
    <script src="https://cdn.jsdelivr.net/npm/clipboard@1/dist/clipboard.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.1.1/anchor.min.js"></script>
  </head>

  <body class="layout--textbook">

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

    <div class="initial-content">
      



<div id="main" class="textbook" role="main">
  <div id="textbook_wrapper">
    
  <div class="sidebar sticky textbook">
  
  
    <img src="/dsfe/images/dsfe_logo.png" class="textbook_logo" />
    

    
      

<nav class="nav__list">
  
  <input id="ac-toc" name="accordion-toc" type="checkbox" />
  <label for="ac-toc">Toggle Menu</label>
  <ul class="nav__items">
    
      <li>
        
          
          

          <a href="/dsfe/"><span class="nav__sub-title">Home</span></a>
        

        
      </li>
    
      <li>
        
          
          

          <a href="/dsfe/chapters/01/what-is-data-science"><span class="nav__sub-title">1. Data Science</span></a>
        

        
        <ul>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/01/intro" class="level_1">1.1 Introduction</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/01/computational-tools" class="level_2">1.1.1 Computational Tools</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/01/statistical-techniques" class="level_2">1.1.2 Statistical Techniques</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/01/why-data-science" class="level_1">1.2 Why Data Science?</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/01/Plotting_the_Classics" class="level_1">1.3 Plotting the Classics</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/01/Literary_Characters" class="level_2">1.3.1 Literary Characters</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/01/Another_Kind_Of_Character" class="level_2">1.3.2 Another Kind of Character</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          
          

          <a href="/dsfe/chapters/02/to_code"><span class="nav__sub-title">2. Programming</span></a>
        

        
        <ul>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/02/sampling_problem" class="level_1">2.1 A sampling problem</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/02/three_girls" class="level_1">2.2 A simpler problem</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/02/Expressions" class="level_1">2.3 Expressions</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/02/variables" class="level_1">2.4 Variables</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/02/Names" class="level_1">2.5 Names</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/02/Calls" class="level_1">2.6 Call expressions</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          
          

          <a href="/dsfe/chapters/03/data_types"><span class="nav__sub-title">3. Data types</span></a>
        

        
        <ul>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/03/Numbers" class="level_1">3.1 Numbers</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/03/Strings" class="level_1">3.2 Strings</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/03/Comparison" class="level_1">3.3 Comparison</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/03/Arrays" class="level_1">3.4 Arrays</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/03/Ranges" class="level_1">3.5 Ranges</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/03/More_on_Arrays" class="level_1">3.6 More on arrays</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/03/arrays_and_axes" class="level_1">3.7 Arrays and axes</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/03/reply_supreme" class="level_1">3.8 Reply to the Supreme Court</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/03/three_girls" class="level_1">3.9 Revision - three girls</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/03/array_indexing" class="level_1">3.10 Selecting with arrays</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          
          

          <a href="/dsfe/chapters/04/data_frames"><span class="nav__sub-title">4. Data frames</span></a>
        

        
        <ul>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/04/data_frame_intro" class="level_1">4.1 Introduction to data frames</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          
          

          <a href="/dsfe/chapters/05/permutation"><span class="nav__sub-title">5. Permutations</span></a>
        

        
        <ul>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/05/population_permutation" class="level_1">5.1 Population and permutation</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/05/lists" class="level_1">5.2 lists</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/05/iteration" class="level_1">5.3 Iteration with For loops</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/05/indentation" class="level_1">5.4 Indentation, indentation</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/05/ones_zeros" class="level_1">5.5 Ones and zeros</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/05/brexit_ages" class="level_1">5.6 A permutation test</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          
          

          <a href="/dsfe/chapters/06/more_simulation"><span class="nav__sub-title">6. More on simulation</span></a>
        

        
        <ul>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/06/sorting_arrays" class="level_1">6.1 Sorting arrays</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/06/monty_hall" class="level_1">6.2 Monty hall problem</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          
          

          <a href="/dsfe/chapters/07/more_building_blocks"><span class="nav__sub-title">7. More building blocks</span></a>
        

        
        <ul>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/07/none" class="level_1">7.2 None</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/07/functions" class="level_1">7.1 Functions</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/07/functions_as_values" class="level_1">7.1 Functions as values</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/07/conditional_statements" class="level_1">7.2 Conditional statements</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          
          

          <a href="/dsfe/chapters/08/mean"><span class="nav__sub-title">8. The mean and straight line relationships</span></a>
        

        
        <ul>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/08/mean_meaning" class="level_1">8.1 The mean as a predictor</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/08/where_and_argmin" class="level_1">8.2 Where and argmin</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/08/mean_and_slopes" class="level_1">8.3 Mean and slopes</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/08/optimization" class="level_1">8.4 Optimization</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/08/finding_lines" class="level_1">8.5 Finding lines</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/08/inference_on_slopes" class="level_1">8.6 Believable slopes</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          
          

          <a href="/dsfe/chapters/09/classification"><span class="nav__sub-title">9. Classification</span></a>
        

        
        <ul>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/09/standard_scores" class="level_1">9.1 Standard scores</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/09/Nearest_Neighbors" class="level_1">9.2 Nearest neighbors</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/09/Training_and_Testing" class="level_1">9.3 Training and testing</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/09/Rows_of_Tables" class="level_1">9.4 Rows of tables</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/09/Implementing_the_Classifier" class="level_1">9.5 Implementing the classifier</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/09/Accuracy_of_the_Classifier" class="level_1">9.6 Accuracy of the classifier</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          
          

          <a href="/dsfe/chapters/exercises/exercises"><span class="nav__sub-title">Exercises</span></a>
        

        
        <ul>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/exercises/simulation" class="level_1">Simulation</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/exercises/df_exercises" class="level_1">Data frames</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/exercises/brexit_analysis" class="level_1">Brexit analysis</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/exercises/for_loops" class="level_1">For loops</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/exercises/money_and_death" class="level_1">Money and death</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/exercises/function_exercises" class="level_1">Function exercises</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/exercises/functions_values_exercises" class="level_1">Function as values exercises</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/exercises/conditional_statements_exercises" class="level_1">Conditional statement exercises</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          
          

          <a href="/dsfe/chapters/extra/extra"><span class="nav__sub-title">Extra pages</span></a>
        

        
        <ul>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/extra/more_on_lists" class="level_1">More on lists</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/extra/monty_hall_lists" class="level_1">Monty Hall with lists</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/extra/data8_functions" class="level_1">Berkeley introduction to functions</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/extra/mean_deviations" class="level_1">Deviations around the mean</a></li>
          
        </ul>
        
      </li>
    
  </ul>
</nav>

    

  
  </div>


    <article class="page textbook" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="headline" content="9.5 Accuracy of the classifier">
      <meta itemprop="description" content="You can download the file fromwine.csv.">
      <meta itemprop="datePublished" content="March 29, 2019">
      

      <div class="page__inner-wrap">
        
          <header>
            <h1 id="page-title" class="page__title" itemprop="headline">9.5 Accuracy of the classifier
</h1>
          </header>
        

        <section class="page__content" itemprop="text">
          
            

<!-- TOC will only show up if it has at least one item -->


  <aside class="sidebar__right">
    <nav class="toc">
      <header><h4 class="nav__title"><i class="fas fa-list-ul"></i>   On this page</h4></header>
      <ul class="toc__menu">
  <li><a href="#the-accuracy-of-the-classifier">The Accuracy of the Classifier</a></li>
  <li><a href="#measuring-the-accuracy-of-our-wine-classifier">Measuring the Accuracy of Our Wine Classifier</a></li>
  <li><a href="#breast-cancer-diagnosis">Breast Cancer Diagnosis</a></li>
</ul>
    </nav>
  </aside>


          
          <!-- INTERACT LINKS -->

    
    
    <a class="notebook-link" href="https://matthew-brett.github.io/dsfe/notebooks/09/Accuracy_of_the_Classifier.ipynb">Download notebook</a>
    <a class="interact-button" href="https://mybinder.org/v2/gh/matthew-brett/dsfe/master?filepath=notebooks%2F09%2FAccuracy_of_the_Classifier.ipynb">Interact</a>


          <p>You can download the file from
<a href="/dsfe/data/wine.csv">wine.csv</a>.</p>

<h3 id="the-accuracy-of-the-classifier">The Accuracy of the Classifier</h3>

<p>To see how well our classifier does, we might put 50% of the data into the training set and the other 50% into the test set.  Basically, we are setting aside some data for later use, so we can use it to measure the accuracy of our classifier.  We’ve been calling that the <em>test set</em>. Sometimes people will call the data that you set aside for testing a <em>hold-out set</em>, and they’ll call this strategy for estimating accuracy the <em>hold-out method</em>.</p>

<p>Note that this approach requires great discipline.  Before you start applying machine learning methods, you have to take some of your data and set it aside for testing.  You must avoid using the test set for developing your classifier: you shouldn’t use it to help train your classifier or tweak its settings or for brainstorming ways to improve your classifier.  Instead, you should use it only once, at the very end, after you’ve finalized your classifier, when you want an unbiased estimate of its accuracy.</p>

<h3 id="measuring-the-accuracy-of-our-wine-classifier">Measuring the Accuracy of Our Wine Classifier</h3>
<p>OK, so let’s apply the hold-out method to evaluate the effectiveness of the $k$-nearest neighbor classifier for identifying wines.  The data set has 178 wines, so we’ll randomly permute the data set and put 89 of them in the training set and the remaining 89 in the test set.</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">n_wine</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">wine</span><span class="p">)</span>
<span class="n">shuffled_wine</span> <span class="o">=</span> <span class="n">wine</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">n_wine</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">training_set</span> <span class="o">=</span> <span class="n">shuffled_wine</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="mi">89</span><span class="p">]</span>
<span class="n">test_set</span>  <span class="o">=</span> <span class="n">shuffled_wine</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">89</span><span class="p">:]</span>
</code></pre></div></div>

<p>We’ll train the classifier using the 89 wines in the training set, and evaluate how well it performs on the test set. To make our lives easier, we’ll write a function to evaluate a classifier on every wine in the test set:</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">count_zero</span><span class="p">(</span><span class="n">array</span><span class="p">):</span>
    <span class="s">"""Counts the number of 0's in an array"""</span>
    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">array</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">array</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">count_equal</span><span class="p">(</span><span class="n">array1</span><span class="p">,</span> <span class="n">array2</span><span class="p">):</span>
    <span class="s">"""Takes two numerical arrays of equal length
    and counts the indices where the two are equal"""</span>
    <span class="k">return</span> <span class="n">count_zero</span><span class="p">(</span><span class="n">array1</span> <span class="o">-</span> <span class="n">array2</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">evaluate_accuracy</span><span class="p">(</span><span class="n">training</span><span class="p">,</span> <span class="n">test</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
    <span class="n">test_attributes</span> <span class="o">=</span> <span class="n">test</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="s">'Class'</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">classify_testrow</span><span class="p">(</span><span class="n">row</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">classify</span><span class="p">(</span><span class="n">training</span><span class="p">,</span> <span class="n">row</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">test_attributes</span><span class="o">.</span><span class="nb">apply</span><span class="p">(</span><span class="n">classify_testrow</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">count_equal</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">test</span><span class="p">[</span><span class="s">'Class'</span><span class="p">])</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>
</code></pre></div></div>

<p>Now for the grand reveal – let’s see how we did.  We’ll arbitrarily use $k=5$.</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">evaluate_accuracy</span><span class="p">(</span><span class="n">training_set</span><span class="p">,</span> <span class="n">test_set</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
</code></pre></div></div>

<div class="output_data_text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0.9213483146067416
</code></pre></div></div>

<p>The accuracy rate isn’t bad at all for a simple classifier.</p>

<h3 id="breast-cancer-diagnosis">Breast Cancer Diagnosis</h3>

<p>Now I want to do an example based on diagnosing breast cancer.  I was inspired by Brittany Wenger, who won the Google national science fair in 2012 a 17-year old high school student.  Here’s Brittany:</p>

<p><img src="http://i.huffpost.com/gen/701499/thumbs/o-GSF83-570.jpg?3" alt="Brittany Wenger" /></p>

<p>Brittany’s science fair project was to build a classification algorithm to diagnose breast cancer.  She won grand prize for building an algorithm whose accuracy was almost 99%.</p>

<p>Let’s see how well we can do, with the ideas we’ve learned in this course.</p>

<p>So, let me tell you a little bit about the data set.  Basically, if a woman has a lump in her breast, the doctors may want to take a biopsy to see if it is cancerous.  There are several different procedures for doing that.  Brittany focused on fine needle aspiration (FNA), because it is less invasive than the alternatives.  The doctor gets a sample of the mass, puts it under a microscope, takes a picture, and a trained lab tech analyzes the picture to determine whether it is cancer or not.  We get a picture like one of the following:</p>

<p><img src="/dsfe/images/benign.png" alt="benign" /></p>

<p><img src="/dsfe/images/malignant.png" alt="cancer" /></p>

<p>Unfortunately, distinguishing between benign vs malignant can be tricky.  So, researchers have studied the use of machine learning to help with this task.  The idea is that we’ll ask the lab tech to analyze the image and compute various attributes: things like the typical size of a cell, how much variation there is among the cell sizes, and so on.  Then, we’ll try to use this information to predict (classify) whether the sample is malignant or not.  We have a training set of past samples from women where the correct diagnosis is known, and we’ll hope that our machine learning algorithm can use those to learn how to predict the diagnosis for future samples.</p>

<p>We end up with the following data set.  For the “Class” column, 1 means malignant (cancer); 0 means benign (not cancer).</p>

<p>Download the file from <a href="/dsfe/data/breast-cancer.csv">breast-cancer.csv</a>.</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">patients</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'breast-cancer.csv'</span><span class="p">)</span>
<span class="n">patients</span> <span class="o">=</span> <span class="n">patients</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="s">'ID'</span><span class="p">)</span>
<span class="n">patients</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div>
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Clump Thickness</th>
      <th>Uniformity of Cell Size</th>
      <th>Uniformity of Cell Shape</th>
      <th>Marginal Adhesion</th>
      <th>Single Epithelial Cell Size</th>
      <th>Bare Nuclei</th>
      <th>Bland Chromatin</th>
      <th>Normal Nucleoli</th>
      <th>Mitoses</th>
      <th>Class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>3</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>5</td>
      <td>4</td>
      <td>4</td>
      <td>5</td>
      <td>7</td>
      <td>10</td>
      <td>3</td>
      <td>2</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
      <td>2</td>
      <td>3</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>6</td>
      <td>8</td>
      <td>8</td>
      <td>1</td>
      <td>3</td>
      <td>4</td>
      <td>3</td>
      <td>7</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>1</td>
      <td>1</td>
      <td>3</td>
      <td>2</td>
      <td>1</td>
      <td>3</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>
</div>

<p>So we have 9 different attributes.  I don’t know how to make a 9-dimensional scatterplot of all of them, so I’m going to pick two and plot them:</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">patients_with_colors</span> <span class="o">=</span> <span class="n">patients</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">patients_with_colors</span><span class="p">[</span><span class="s">'Color'</span><span class="p">]</span> <span class="o">=</span> <span class="s">'darkblue'</span>
<span class="n">patients_with_colors</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">patients</span><span class="p">[</span><span class="s">'Class'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="s">'Color'</span><span class="p">]</span> <span class="o">=</span> <span class="s">'gold'</span>
</code></pre></div></div>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">patients_with_colors</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
    <span class="s">'Bland Chromatin'</span><span class="p">,</span>
    <span class="s">'Single Epithelial Cell Size'</span><span class="p">,</span>
    <span class="n">c</span><span class="o">=</span><span class="n">patients_with_colors</span><span class="p">[</span><span class="s">'Color'</span><span class="p">]);</span>
</code></pre></div></div>

<p><img src="../../images/chapters/09/Accuracy_of_the_Classifier_13_0.png" alt="png" /></p>

<p>Oops.  That plot is utterly misleading, because there are a bunch of points that have identical values for both the x- and y-coordinates.  To make it easier to see all the data points, I’m going to add a little bit of random jitter to the x- and y-values.  Here’s how that looks:</p>

<p><img src="../../images/chapters/09/Accuracy_of_the_Classifier_15_0.png" alt="png" /></p>

<p>For instance, you can see there are lots of samples with chromatin = 2 and epithelial cell size = 2; all non-cancerous.</p>

<p>Keep in mind that the jittering is just for visualization purposes, to make it easier to get a feeling for the data.  We’re ready to work with the data now, and we’ll use the original (unjittered) data.</p>

<p>First we’ll create a training set and a test set. The data set has 683 patients, so we’ll randomly permute the data set and put 342 of them in the training set and the remaining 341 in the test set.</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">n_patients</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">patients</span><span class="p">)</span>
<span class="n">shuffled_patients</span> <span class="o">=</span> <span class="n">patients</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">n_patients</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">training_set</span> <span class="o">=</span> <span class="n">shuffled_patients</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="mi">342</span><span class="p">]</span>
<span class="n">test_set</span> <span class="o">=</span> <span class="n">shuffled_patients</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">342</span><span class="p">:]</span>
</code></pre></div></div>

<p>Let’s stick with 5 nearest neighbors, and see how well our classifier does.</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">evaluate_accuracy</span><span class="p">(</span><span class="n">training_set</span><span class="p">,</span> <span class="n">test_set</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
</code></pre></div></div>

<div class="output_data_text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0.9706744868035191
</code></pre></div></div>

<p>Over 96% accuracy.  Not bad!  Once again, pretty darn good for such a simple technique.</p>

<p>As a footnote, you might have noticed that Brittany Wenger did even better.  What techniques did she use? One key innovation is that she incorporated a confidence score into her results: her algorithm had a way to determine when it was not able to make a confident prediction, and for those patients, it didn’t even try to predict their diagnosis.  Her algorithm was 99% accurate on the patients where it made a prediction – so that extension seemed to help quite a bit.</p>

<div class="isa_info">
<i class="fa fa-info-circle"></i>
This page has content from the
<a href="https://github.com/data-8/textbook/blob/64b20f0/notebooks/Accuracy_of_the_Classifier.ipynb">
Accuracy_of_the_Classifier</a>
notebook from the UC Berkeley course.  See the Berkeley course section of the
<a href="/dsfe/license">license</a>
</div>


          
        </section>

        <footer class="page__meta">
          
          


        </footer>

        

        
  <nav class="pagination">
    
      <a href="/dsfe/chapters/09/Implementing_the_Classifier" class="pagination--pager" title="9.4 Implementing the classifier
">Previous</a>
    
    
      <a href="/dsfe/chapters/exercises/exercises" class="pagination--pager" title="Exercises
">Next</a>
    
  </nav>


      </div>

      
    </article>
  </div>
</div>

    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><input type="text" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
    <div id="results" class="results"></div></div>
      </div>
    

    

    
  <script src="/dsfe/assets/js/main.min.js"></script>
  <script src="https://use.fontawesome.com/releases/v5.0.12/js/all.js"></script>




<script src="/dsfe/assets/js/lunr/lunr.min.js"></script>
<script src="/dsfe/assets/js/lunr/lunr-store.js"></script>
<script src="/dsfe/assets/js/lunr/lunr-en.js"></script>




    <!-- Custom scripts to load after site JS is loaded -->

    <!-- Custom HTML used for the textbooks -->
<!-- Configure, then load MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true,
      processEnvironments: true
    }
  };
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML-full,Safe" type="text/javascript"></script>


<script type="text/javascript">
// --- To auto-embed hub URLs in interact links if given in a RESTful fashion ---
function getJsonFromUrl(url) {
  var query = url.split('?');
  if (query.length < 2) {
    // No queries so just return false
    return false;
  }
  query = query[1];
  // Collect REST params into a dictionary
  var result = {};
  query.split("&").forEach(function(part) {
    var item = part.split("=");
    result[item[0]] = decodeURIComponent(item[1]);
  });
  return result;
}

// Parse a Binder URL, converting it to the string needed for JupyterHub
function binder2Jupyterhub(url) {
  newUrl = {};
  parts = url.split('v2/gh/')[1];
  // Grab the base repo information
  repoinfo = parts.split('?')[0];
  var [org, repo, ref] = repoinfo.split('/');
  newUrl['repo'] = ['https://github.com', org, repo].join('/');
  newUrl['branch'] = ref
  // Grab extra parameters passed
  params = getJsonFromUrl(url);
  if (params['filepath'] !== undefined) {
    newUrl['subPath'] = params['filepath']
  }
  return jQuery.param(newUrl);
}

// Filter out potentially unsafe characters to prevent xss
function safeUrl(url)
{
   return String(encodeURIComponent(url))
            .replace(/&/g, '&amp;')
            .replace(/"/g, '&quot;')
            .replace(/'/g, '&#39;')
            .replace(/</g, '&lt;')
            .replace(/>/g, '&gt;');
}

function addParamToInternalLinks(hub) {
  var links = $("a").each(function() {
    var href = this.href;
    // If the link is an internal link...
    if (href.search("https://matthew-brett.github.io") !== -1 || href.startsWith('/') || href.search("127.0.0.1:") !== -1) {
      // Assume we're an internal link, add the hub param to it
      var params = getJsonFromUrl(href);
      if (params !== false) {
        // We have REST params, so append a new one
        params['hub'] = hub;
      } else {
        // Create the REST params
        params = {'hub': hub};
      }
      // Update the link
      var newHref = href.split('?')[0] + '?' + jQuery.param(params);
      this.setAttribute('href', decodeURIComponent(newHref));
    }
  });
  return false;
}

  // Update interact links
function updateInteractLink() {
    // hack to make this work since it expects a ? in the URL
    rest = getJsonFromUrl("?" + location.search.substr(1));
    hubUrl = rest['hub'];
    if (hubUrl !== undefined) {
      // Sanitize the hubUrl
      hubUrl = safeUrl(hubUrl);
      // Add HTTP text if omitted
      if (hubUrl.indexOf('http') < 0) {hubUrl = 'http://' + hubUrl;}
      link = $("a.interact-button")[0];
      if (link !== undefined) {
          // Update the interact link URL
          var href = link.getAttribute('href');
          if ('binder' == 'binder') {
            // If binder links exist, we need to re-work them for jupyterhub
            first = [hubUrl, 'hub', 'user-redirect', 'git-sync'].join('/')
            href = first + '?' + binder2Jupyterhub(href);
          } else {
            // If JupyterHub links, we only need to replace the hub url
            href = href.replace("https://mybinder.org", hubUrl);
          }
          link.setAttribute('href', decodeURIComponent(href));

          // Add text after interact link saying where we're launching
          hubUrlNoHttp = decodeURIComponent(hubUrl).replace('http://', '').replace('https://', '');
          $("a.interact-button").after($('<div class="interact-context">on ' + hubUrlNoHttp + '</div>'));

      }
      // Update internal links so we retain the hub url
      addParamToInternalLinks(hubUrl);
    }
}

// --- Highlight the part of sidebar for current page ---

// helper to replace trailing slash
function replaceSlash(string)
{
    return string.replace(/\/$/, "");
}

// Add a class to the current page in the sidebar
function highlightSidebarCurrentPage()
{
  var currentpage = location.href;
  var links = $('.sidebar .nav__items a');
  var ii = 0;
  for(ii; ii < links.length; ii++) {
    var link = links[ii];
    if(replaceSlash(link.href) == replaceSlash(currentpage)) {
      // Add CSS for styling
      link.classList.add("current");
      // Scroll to this element
      $('div.sidebar').scrollTop(link.offsetTop - 300);
    }
  }
}

// --- Set up copy/paste for code blocks ---
function addCopyButtonToCode(){
  // get all <code> elements
  var allCodeBlocksElements = $( "div.input_area code, div.highlighter-rouge code" );

  allCodeBlocksElements.each(function(ii) {
   	// add different id for each code block

  	// target
    var currentId = "codeblock" + (ii + 1);
    $(this).attr('id', currentId);

    //trigger
    var clipButton = '<button class="btn copybtn" data-clipboard-target="#' + currentId + '"><img src="https://clipboardjs.com/assets/images/clippy.svg" width="13" alt="Copy to clipboard"></button>';
       $(this).after(clipButton);
    });

    new Clipboard('.btn');
}

// Run scripts when page is loaded
$(document).ready(function () {
  // Add anchors to H1 etc links
  anchors.add();
  // Highlight current page in sidebar
  highlightSidebarCurrentPage();
  // Add copy button to code blocks
  addCopyButtonToCode();
  // Update the Interact link if a REST param given
  updateInteractLink();
});
</script>

  </body>
</html>
