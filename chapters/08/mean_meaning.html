<!doctype html>
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>8.1 The mean as a predictor - Data Science for Everyone</title>
<meta name="description" content="The mean is an interesting value.">



<meta property="og:type" content="article">
<meta property="og:locale" content="en_UK">
<meta property="og:site_name" content="Data Science for Everyone">
<meta property="og:title" content="8.1 The mean as a predictor">
<meta property="og:url" content="https://matthew-brett.github.io/dsfe/chapters/08/mean_meaning">


  <meta property="og:description" content="The mean is an interesting value.">







  <meta property="article:published_time" content="2019-02-15T00:37:27+00:00">





  

  


<link rel="canonical" href="https://matthew-brett.github.io/dsfe/chapters/08/mean_meaning">







  <script type="application/ld+json">
    {
      "@context": "http://schema.org",
      "@type": "Person",
      "name": "Matthew Brett",
      "url": "https://matthew-brett.github.io/dsfe",
      "sameAs": null
    }
  </script>







<!-- end _includes/seo.html -->


<link href="/dsfe/feed.xml" type="application/atom+xml" rel="alternate" title="Data Science for Everyone Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/dsfe/assets/css/main.css">

<!--[if lte IE 9]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->


    <!-- start custom head snippets -->


<!-- end custom head snippets -->

    <link rel="stylesheet" href="/dsfe/assets/css/notebook-markdown.css">
    <link rel="stylesheet" href="/dsfe/assets/css/custom.css">
    <link rel="shortcut icon" type="image/png" href="/dsfe/favicon.png">
    <script src="https://cdn.jsdelivr.net/npm/clipboard@1/dist/clipboard.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.1.1/anchor.min.js"></script>
  </head>

  <body class="layout--textbook">

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

    <div class="initial-content">
      



<div id="main" class="textbook" role="main">
  <div id="textbook_wrapper">
    
  <div class="sidebar sticky textbook">
  
  
    <img src="/dsfe/images/dsfe_logo.png" class="textbook_logo" />
    

    
      

<nav class="nav__list">
  
  <input id="ac-toc" name="accordion-toc" type="checkbox" />
  <label for="ac-toc">Toggle Menu</label>
  <ul class="nav__items">
    
      <li>
        
          
          

          <a href="/dsfe/"><span class="nav__sub-title">Home</span></a>
        

        
      </li>
    
      <li>
        
          
          

          <a href="/dsfe/chapters/01/what-is-data-science"><span class="nav__sub-title">1. Data Science</span></a>
        

        
        <ul>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/01/intro" class="level_1">1.1 Introduction</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/01/computational-tools" class="level_2">1.1.1 Computational Tools</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/01/statistical-techniques" class="level_2">1.1.2 Statistical Techniques</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/01/why-data-science" class="level_1">1.2 Why Data Science?</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/01/Plotting_the_Classics" class="level_1">1.3 Plotting the Classics</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/01/Literary_Characters" class="level_2">1.3.1 Literary Characters</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/01/Another_Kind_Of_Character" class="level_2">1.3.2 Another Kind of Character</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          
          

          <a href="/dsfe/chapters/02/to_code"><span class="nav__sub-title">2. Programming</span></a>
        

        
        <ul>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/02/sampling_problem" class="level_1">2.1 A sampling problem</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/02/three_girls" class="level_1">2.2 A simpler problem</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/02/Expressions" class="level_1">2.3 Expressions</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/02/variables" class="level_1">2.4 Variables</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/02/Names" class="level_1">2.5 Names</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/02/Calls" class="level_1">2.6 Call expressions</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          
          

          <a href="/dsfe/chapters/03/data_types"><span class="nav__sub-title">3. Data types</span></a>
        

        
        <ul>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/03/Numbers" class="level_1">3.1 Numbers</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/03/Strings" class="level_1">3.2 Strings</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/03/Comparison" class="level_1">3.3 Comparison</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/03/Arrays" class="level_1">3.4 Arrays</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/03/Ranges" class="level_1">3.5 Ranges</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/03/More_on_Arrays" class="level_1">3.6 More on arrays</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/03/arrays_and_axes" class="level_1">3.7 Arrays and axes</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/03/reply_supreme" class="level_1">3.8 Reply to the Supreme Court</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/03/three_girls" class="level_1">3.9 Revision - three girls</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/03/array_indexing" class="level_1">3.10 Selecting with arrays</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          
          

          <a href="/dsfe/chapters/04/data_frames"><span class="nav__sub-title">4. Data frames</span></a>
        

        
        <ul>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/04/data_frame_intro" class="level_1">4.1 Introduction to data frames</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          
          

          <a href="/dsfe/chapters/05/permutation"><span class="nav__sub-title">5. Permutations</span></a>
        

        
        <ul>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/05/population_permutation" class="level_1">5.1 Population and permutation</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/05/lists" class="level_1">5.2 lists</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/05/iteration" class="level_1">5.3 Iteration with For loops</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/05/indentation" class="level_1">5.4 Indentation, indentation</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/05/ones_zeros" class="level_1">5.5 Ones and zeros</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/05/brexit_ages" class="level_1">5.6 Brexit ages</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          
          

          <a href="/dsfe/chapters/06/more_simulation"><span class="nav__sub-title">6. More on simulation</span></a>
        

        
        <ul>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/06/sorting_arrays" class="level_1">6.1 Sorting arrays</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/06/monty_hall" class="level_1">6.2 Monty hall problem</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          
          

          <a href="/dsfe/chapters/07/more_building_blocks"><span class="nav__sub-title">7. More building blocks</span></a>
        

        
        <ul>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/07/none" class="level_1">7.2 None</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/07/functions" class="level_1">7.1 Functions</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/07/functions_as_values" class="level_1">7.1 Functions as values</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/07/conditional_statements" class="level_1">7.2 Conditional statements</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          
          

          <a href="/dsfe/chapters/08/mean"><span class="nav__sub-title">8. The mean and straight line relationships</span></a>
        

        
        <ul>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/08/mean_meaning" class="level_1">8.1 The mean as a predictor</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          
          

          <a href="/dsfe/chapters/exercises/exercises"><span class="nav__sub-title">Exercises</span></a>
        

        
        <ul>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/exercises/simulation" class="level_1">Simulation</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/exercises/df_exercises" class="level_1">Data frames</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/exercises/brexit_analysis" class="level_1">Brexit analysis</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/exercises/for_loops" class="level_1">For loops</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/exercises/money_and_death" class="level_1">Money and death</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/exercises/function_exercises" class="level_1">Function exercises</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/exercises/functions_values_exercises" class="level_1">Function as values exercises</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/exercises/conditional_statements_exercises" class="level_1">Conditional statement exercises</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          
          

          <a href="/dsfe/chapters/extra/extra"><span class="nav__sub-title">Extra pages</span></a>
        

        
        <ul>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/extra/more_on_lists" class="level_1">More on lists</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/extra/monty_hall_lists" class="level_1">Monty Hall with lists</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/extra/data8_functions" class="level_1">Berkeley introduction to functions</a></li>
          
            
            

            
            

            

            <li><a href="/dsfe/chapters/extra/mean_deviations" class="level_1">Deviations around the mean</a></li>
          
        </ul>
        
      </li>
    
  </ul>
</nav>

    

  
  </div>


    <article class="page textbook" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="headline" content="8.1 The mean as a predictor">
      <meta itemprop="description" content="The mean is an interesting value.">
      <meta itemprop="datePublished" content="February 15, 2019">
      

      <div class="page__inner-wrap">
        
          <header>
            <h1 id="page-title" class="page__title" itemprop="headline">8.1 The mean as a predictor
</h1>
          </header>
        

        <section class="page__content" itemprop="text">
          
            

<!-- TOC will only show up if it has at least one item -->



          
          <!-- INTERACT LINKS -->

    
    
    <a class="notebook-link" href="https://matthew-brett.github.io/dsfe/notebooks/08/mean_meaning.ipynb">Download notebook</a>
    <a class="interact-button" href="https://mybinder.org/v2/gh/matthew-brett/dsfe/master?filepath=notebooks%2F08%2Fmean_meaning.ipynb">Interact</a>


          <p>The mean is an interesting value.</p>

<p>In this notebook, we fetch an example sequence of numbers, with a distribution that is far from the standard bell-curve distribution.  We look at the properties of the mean as a predictor of the whole distribution.</p>

<p>First we load our usual libraries.</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="c1"># Make plots look a little bit more fancy
</span><span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s">'fivethirtyeight'</span><span class="p">)</span>
<span class="c1"># Print to 2 decimal places, show tiny values as 0
</span><span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">precision</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">suppress</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<p>We need Pandas to load the gender data that we first saw in the <a href="../04/data_frame_intro">data frame introduction</a>.</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
</code></pre></div></div>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Load the data file
</span><span class="n">gender_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'gender_stats.csv'</span><span class="p">)</span>
</code></pre></div></div>

<p>In this case, we are only interested in the data for the Maternal Mortality Ration <code class="highlighter-rouge">mat_mort_ratio</code>.</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">mat_mort_ratio</span> <span class="o">=</span> <span class="n">gender_data</span><span class="p">[</span><span class="s">'mat_mort_ratio'</span><span class="p">]</span>
</code></pre></div></div>

<p>There are many <code class="highlighter-rouge">NaN</code> values in <code class="highlighter-rouge">mat_mort_ratio</code>.  For simplicity, we drop
these.</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">mat_mort_valid</span> <span class="o">=</span> <span class="n">mat_mort_ratio</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span>
</code></pre></div></div>

<p><code class="highlighter-rouge">mat_mort_valid</code> is a still a Pandas Series:</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">type</span><span class="p">(</span><span class="n">mat_mort_valid</span><span class="p">)</span>
</code></pre></div></div>

<div class="output_data_text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pandas.core.series.Series
</code></pre></div></div>

<p>Again, to make things a bit simpler, we convert this Series to an ordinary Numpy array:</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">mm_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">mat_mort_valid</span><span class="p">)</span>
</code></pre></div></div>

<p>The values for <code class="highlighter-rouge">mm_arr</code> are very far from a standard bell-curve or <a href="https://en.wikipedia.org/wiki/Normal_distribution">normal distribution</a>.</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">mm_arr</span><span class="p">);</span>
</code></pre></div></div>

<p><img src="../../images/chapters/08/mean_meaning_14_0.png" alt="png" /></p>

<p>We are interested in the <em>mean</em>.</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">mm_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">mm_arr</span><span class="p">)</span>
<span class="n">mm_mean</span>
</code></pre></div></div>

<div class="output_data_text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>181.4312227074236
</code></pre></div></div>

<p>As you remember, we get the mean by adding up all the values, and then dividing by the number of values, often written as $n$.</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">mm_arr</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">mm_arr</span><span class="p">)</span>
</code></pre></div></div>

<div class="output_data_text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>181.4312227074236
</code></pre></div></div>

<p>Now let’s consider the following situation.</p>

<p>I have all the values on my computer.</p>

<p>You don’t have any of the values.</p>

<p>I want to give you one value, that will do the best possible job of <em>predicting</em> the values.  Call this the <em>predictor</em>.</p>

<p>Then I give you the values from the distribution one by one.  You see how good
your prediction is, by subtracting the <em>predictor</em> from the value I just gave
you.  That is your <em>prediction error</em> for that value.</p>

<p>One value I could give you as a predictor, is the mean.</p>

<p>Is that a good value to give you?</p>

<p>Let’s start by shuffling up the values, ready to give you, one by one.</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Not really necessary, but still
</span><span class="n">mm_shuffled</span> <span class="o">=</span> <span class="n">mm_arr</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">mm_shuffled</span><span class="p">)</span>
</code></pre></div></div>

<p>I give you the mean, as a predictor.</p>

<p>Then I pass you the first value.  You subtract your predictor, to get the prediction error.</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">prediction_error_0</span> <span class="o">=</span> <span class="n">mm_shuffled</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">mm_mean</span>
<span class="n">prediction_error_0</span>
</code></pre></div></div>

<div class="output_data_text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>-118.18122270742359
</code></pre></div></div>

<p>We do the same for the second value:</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">prediction_error_1</span> <span class="o">=</span> <span class="n">mm_shuffled</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">mm_mean</span>
<span class="n">prediction_error_1</span>
</code></pre></div></div>

<div class="output_data_text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>694.3187772925764
</code></pre></div></div>

<p>To cut to the end, let’s do all the values at once:</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Calculate all the prediction errors
</span><span class="n">prediction_errors</span> <span class="o">=</span> <span class="n">mm_shuffled</span> <span class="o">-</span> <span class="n">mm_mean</span>
<span class="c1"># Show the first 10
</span><span class="n">prediction_errors</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
</code></pre></div></div>

<div class="output_data_text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([-118.18,  694.32, -152.18,   63.82,  280.07, -178.43, -177.43,
        -61.43,  710.82, -176.43])
</code></pre></div></div>

<p>What do the prediction errors look like?</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">prediction_errors</span><span class="p">);</span>
</code></pre></div></div>

<p><img src="../../images/chapters/08/mean_meaning_28_0.png" alt="png" /></p>

<p>Notice the by-eye center of this distribution of prediction errors.</p>

<p>Let’s add up all the prediction errors:</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">prediction_errors</span><span class="p">)</span>
</code></pre></div></div>

<div class="output_data_text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2.0463630789890885e-12
</code></pre></div></div>

<p>The prediction errors add up to (very nearly) 0.  This is a property of the
mean.  The deviations from the mean sum to zero.</p>

<p>In fact, it is not very hard to show that the deviations <a href="../extra/mean_deviations">must sum to
zero</a>.</p>

<p>Here was our mean.</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">mm_mean</span>
</code></pre></div></div>

<div class="output_data_text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>181.4312227074236
</code></pre></div></div>

<p>Another prediction we might be interested in, is one that gives us the smallest squared difference from the actual values.</p>

<p>Here are the squared differences from the mean.</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Squared prediction errors, for the mean
</span><span class="n">squared_pes</span> <span class="o">=</span> <span class="n">prediction_errors</span> <span class="o">**</span> <span class="mi">2</span>
<span class="c1"># Show the first ten
</span><span class="n">squared_pes</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
</code></pre></div></div>

<div class="output_data_text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([ 13966.8 , 482078.56,  23159.12,   4072.84,  78438.52,  31837.7 ,
        31481.84,   3773.8 , 505263.33,  31127.98])
</code></pre></div></div>

<p>With a good prediction, we might want these squared prediction errors to be small.  We can see how small these are by adding them all up.  This gives us the “sum of squares”.</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sos</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">squared_pes</span><span class="p">)</span>
<span class="n">sos</span>
</code></pre></div></div>

<div class="output_data_text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>12392168.854257641
</code></pre></div></div>

<p>That is the sum of squared prediction errors that the mean gives us.  Could some other value give us a better (lower) sum of squared prediction error.</p>

<p>Let’s try lots of predictors, to see which gives us the smallest squared prediction error.</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Try lots of values between 150 and 210
</span><span class="n">predictors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">150</span><span class="p">,</span> <span class="mi">210</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="c1"># First 10
</span><span class="n">predictors</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
</code></pre></div></div>

<div class="output_data_text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([150. , 150.1, 150.2, 150.3, 150.4, 150.5, 150.6, 150.7, 150.8,
       150.9])
</code></pre></div></div>

<p>We make a function that accepts the values, and the predictor as arguments, and returns the sum of squares of the prediction errors:</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">sum_of_squares</span><span class="p">(</span><span class="n">vals</span><span class="p">,</span> <span class="n">predictor</span><span class="p">):</span>
    <span class="n">pred_errs</span> <span class="o">=</span> <span class="n">vals</span> <span class="o">-</span> <span class="n">predictor</span>
    <span class="n">sq_pred_errs</span> <span class="o">=</span> <span class="n">pred_errs</span> <span class="o">**</span> <span class="mi">2</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">sq_pred_errs</span><span class="p">)</span>
</code></pre></div></div>

<p>We confirm that this gives us the value we saw before, when we use the mean as a predictor:</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sum_of_squares</span><span class="p">(</span><span class="n">mm_arr</span><span class="p">,</span> <span class="n">mm_mean</span><span class="p">)</span>
</code></pre></div></div>

<div class="output_data_text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>12392168.854257643
</code></pre></div></div>

<p>Here’s what we get if we use the first predictor value:</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sum_of_squares</span><span class="p">(</span><span class="n">mm_arr</span><span class="p">,</span> <span class="n">predictors</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</code></pre></div></div>

<div class="output_data_text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>12618402.9375
</code></pre></div></div>

<p>Now we try all the predictor values, to see which value gives us the lowest sum of squared errors.</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># How many predictors do we have to try?
</span><span class="n">n_predictors</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">predictors</span><span class="p">)</span>
<span class="n">n_predictors</span>
</code></pre></div></div>

<div class="output_data_text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>600
</code></pre></div></div>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># An array to store the sum of squares values for each predictor
</span><span class="n">sos_for_predictors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n_predictors</span><span class="p">)</span>
</code></pre></div></div>

<p>We calculate all the sums of squares:</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_predictors</span><span class="p">):</span>
    <span class="n">predictor</span> <span class="o">=</span> <span class="n">predictors</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="n">sos</span> <span class="o">=</span> <span class="n">sum_of_squares</span><span class="p">(</span><span class="n">mm_arr</span><span class="p">,</span> <span class="n">predictor</span><span class="p">)</span>
    <span class="n">sos_for_predictors</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">sos</span>
</code></pre></div></div>

<p>Which predictor is giving us the lowest value for the sum of squares?</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">predictors</span><span class="p">,</span> <span class="n">sos_for_predictors</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Predictor'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'Sum of squares'</span><span class="p">);</span>
</code></pre></div></div>

<p><img src="../../images/chapters/08/mean_meaning_51_0.png" alt="png" /></p>

<p>The smallest value we found for the sum of squares was:</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">np</span><span class="o">.</span><span class="nb">min</span><span class="p">(</span><span class="n">sos_for_predictors</span><span class="p">)</span>
</code></pre></div></div>

<div class="output_data_text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>12392169.077499999
</code></pre></div></div>

<p>In fact, the value for the mean is even lower:</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sum_of_squares</span><span class="p">(</span><span class="n">mm_arr</span><span class="p">,</span> <span class="n">mm_mean</span><span class="p">)</span>
</code></pre></div></div>

<div class="output_data_text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>12392168.854257643
</code></pre></div></div>

<p>We would have to use some <a href="https://github.com/matthew-brett/biosciences-intro/blob/master/mean_minimizes_ss_deviations.ipynb">simple
calculus</a>
to show this, but the mean has to give the lowest sum of squares error.</p>

<p>Put another way, the mean minimizes:</p>

<ul>
  <li>the sum of the errors;</li>
  <li>the sum of squared errors.</li>
</ul>

          
        </section>

        <footer class="page__meta">
          
          


        </footer>

        

        
  <nav class="pagination">
    
      <a href="/dsfe/chapters/08/mean" class="pagination--pager" title="
  The mean and straight line relationships

">Previous</a>
    
    
      <a href="/dsfe/chapters/exercises/exercises" class="pagination--pager" title="Exercises
">Next</a>
    
  </nav>


      </div>

      
    </article>
  </div>
</div>

    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><input type="text" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
    <div id="results" class="results"></div></div>
      </div>
    

    

    
  <script src="/dsfe/assets/js/main.min.js"></script>
  <script src="https://use.fontawesome.com/releases/v5.0.12/js/all.js"></script>




<script src="/dsfe/assets/js/lunr/lunr.min.js"></script>
<script src="/dsfe/assets/js/lunr/lunr-store.js"></script>
<script src="/dsfe/assets/js/lunr/lunr-en.js"></script>




    <!-- Custom scripts to load after site JS is loaded -->

    <!-- Custom HTML used for the textbooks -->
<!-- Configure, then load MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true,
      processEnvironments: true
    }
  };
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML-full,Safe" type="text/javascript"></script>


<script type="text/javascript">
// --- To auto-embed hub URLs in interact links if given in a RESTful fashion ---
function getJsonFromUrl(url) {
  var query = url.split('?');
  if (query.length < 2) {
    // No queries so just return false
    return false;
  }
  query = query[1];
  // Collect REST params into a dictionary
  var result = {};
  query.split("&").forEach(function(part) {
    var item = part.split("=");
    result[item[0]] = decodeURIComponent(item[1]);
  });
  return result;
}

// Parse a Binder URL, converting it to the string needed for JupyterHub
function binder2Jupyterhub(url) {
  newUrl = {};
  parts = url.split('v2/gh/')[1];
  // Grab the base repo information
  repoinfo = parts.split('?')[0];
  var [org, repo, ref] = repoinfo.split('/');
  newUrl['repo'] = ['https://github.com', org, repo].join('/');
  newUrl['branch'] = ref
  // Grab extra parameters passed
  params = getJsonFromUrl(url);
  if (params['filepath'] !== undefined) {
    newUrl['subPath'] = params['filepath']
  }
  return jQuery.param(newUrl);
}

// Filter out potentially unsafe characters to prevent xss
function safeUrl(url)
{
   return String(encodeURIComponent(url))
            .replace(/&/g, '&amp;')
            .replace(/"/g, '&quot;')
            .replace(/'/g, '&#39;')
            .replace(/</g, '&lt;')
            .replace(/>/g, '&gt;');
}

function addParamToInternalLinks(hub) {
  var links = $("a").each(function() {
    var href = this.href;
    // If the link is an internal link...
    if (href.search("https://matthew-brett.github.io") !== -1 || href.startsWith('/') || href.search("127.0.0.1:") !== -1) {
      // Assume we're an internal link, add the hub param to it
      var params = getJsonFromUrl(href);
      if (params !== false) {
        // We have REST params, so append a new one
        params['hub'] = hub;
      } else {
        // Create the REST params
        params = {'hub': hub};
      }
      // Update the link
      var newHref = href.split('?')[0] + '?' + jQuery.param(params);
      this.setAttribute('href', decodeURIComponent(newHref));
    }
  });
  return false;
}

  // Update interact links
function updateInteractLink() {
    // hack to make this work since it expects a ? in the URL
    rest = getJsonFromUrl("?" + location.search.substr(1));
    hubUrl = rest['hub'];
    if (hubUrl !== undefined) {
      // Sanitize the hubUrl
      hubUrl = safeUrl(hubUrl);
      // Add HTTP text if omitted
      if (hubUrl.indexOf('http') < 0) {hubUrl = 'http://' + hubUrl;}
      link = $("a.interact-button")[0];
      if (link !== undefined) {
          // Update the interact link URL
          var href = link.getAttribute('href');
          if ('binder' == 'binder') {
            // If binder links exist, we need to re-work them for jupyterhub
            first = [hubUrl, 'hub', 'user-redirect', 'git-sync'].join('/')
            href = first + '?' + binder2Jupyterhub(href);
          } else {
            // If JupyterHub links, we only need to replace the hub url
            href = href.replace("https://mybinder.org", hubUrl);
          }
          link.setAttribute('href', decodeURIComponent(href));

          // Add text after interact link saying where we're launching
          hubUrlNoHttp = decodeURIComponent(hubUrl).replace('http://', '').replace('https://', '');
          $("a.interact-button").after($('<div class="interact-context">on ' + hubUrlNoHttp + '</div>'));

      }
      // Update internal links so we retain the hub url
      addParamToInternalLinks(hubUrl);
    }
}

// --- Highlight the part of sidebar for current page ---

// helper to replace trailing slash
function replaceSlash(string)
{
    return string.replace(/\/$/, "");
}

// Add a class to the current page in the sidebar
function highlightSidebarCurrentPage()
{
  var currentpage = location.href;
  var links = $('.sidebar .nav__items a');
  var ii = 0;
  for(ii; ii < links.length; ii++) {
    var link = links[ii];
    if(replaceSlash(link.href) == replaceSlash(currentpage)) {
      // Add CSS for styling
      link.classList.add("current");
      // Scroll to this element
      $('div.sidebar').scrollTop(link.offsetTop - 300);
    }
  }
}

// --- Set up copy/paste for code blocks ---
function addCopyButtonToCode(){
  // get all <code> elements
  var allCodeBlocksElements = $( "div.input_area code, div.highlighter-rouge code" );

  allCodeBlocksElements.each(function(ii) {
   	// add different id for each code block

  	// target
    var currentId = "codeblock" + (ii + 1);
    $(this).attr('id', currentId);

    //trigger
    var clipButton = '<button class="btn copybtn" data-clipboard-target="#' + currentId + '"><img src="https://clipboardjs.com/assets/images/clippy.svg" width="13" alt="Copy to clipboard"></button>';
       $(this).after(clipButton);
    });

    new Clipboard('.btn');
}

// Run scripts when page is loaded
$(document).ready(function () {
  // Add anchors to H1 etc links
  anchors.add();
  // Highlight current page in sidebar
  highlightSidebarCurrentPage();
  // Add copy button to code blocks
  addCopyButtonToCode();
  // Update the Interact link if a REST param given
  updateInteractLink();
});
</script>

  </body>
</html>
