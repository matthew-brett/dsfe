<!doctype html>
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Data Science for Everyone</title>
<meta name="description" content="">



<meta property="og:type" content="website">
<meta property="og:locale" content="en_UK">
<meta property="og:site_name" content="Data Science for Everyone">
<meta property="og:title" content="Data Science for Everyone">
<meta property="og:url" content="https://matthew-brett.github.io/dsfe/notebooks/09/Rows_of_Tables.Rmd">












  

  


<link rel="canonical" href="https://matthew-brett.github.io/dsfe/notebooks/09/Rows_of_Tables.Rmd">







  <script type="application/ld+json">
    {
      "@context": "http://schema.org",
      "@type": "Person",
      "name": "Matthew Brett",
      "url": "https://matthew-brett.github.io/dsfe",
      "sameAs": null
    }
  </script>







<!-- end _includes/seo.html -->


<link href="/dsfe/feed.xml" type="application/atom+xml" rel="alternate" title="Data Science for Everyone Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/dsfe/assets/css/main.css">

<!--[if lte IE 9]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->


    <!-- start custom head snippets -->


<!-- end custom head snippets -->

    <link rel="stylesheet" href="/dsfe/assets/css/notebook-markdown.css">
    <link rel="stylesheet" href="/dsfe/assets/css/custom.css">
    <link rel="shortcut icon" type="image/png" href="/dsfe/favicon.png">
    <script src="https://cdn.jsdelivr.net/npm/clipboard@1/dist/clipboard.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.1.1/anchor.min.js"></script>
  </head>

  <body class="layout--single">

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    
    <div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <a class="site-title" href="/dsfe/">
          <img src="/dsfe/images/dsfe_logo.png" class="masthead_logo" />
          Data Science for Everyone
        </a>
        <ul class="visible-links">
          
            
            <li class="masthead__menu-item">
              <a href="https://matthew-brett.github.io/dsfe/about" >About</a>
            </li>
          
            
            <li class="masthead__menu-item">
              <a href="https://matthew-brett.github.io/dsfe/syllabus" >Syllabus</a>
            </li>
          
            
            <li class="masthead__menu-item">
              <a href="https://matthew-brett.github.io/dsfe/classes" >Classes</a>
            </li>
          
          
            <li class="masthead__menu-item">
              <a href="/dsfe/chapters/01/intro">Textbook</a>
            </li>
          
          
        </ul>
        
        <button class="search__toggle" type="button">
          <svg class="icon" width="16" height="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 15.99 16">
            <path d="M15.5,13.12L13.19,10.8a1.69,1.69,0,0,0-1.28-.55l-0.06-.06A6.5,6.5,0,0,0,5.77,0,6.5,6.5,0,0,0,2.46,11.59a6.47,6.47,0,0,0,7.74.26l0.05,0.05a1.65,1.65,0,0,0,.5,1.24l2.38,2.38A1.68,1.68,0,0,0,15.5,13.12ZM6.4,2A4.41,4.41,0,1,1,2,6.4,4.43,4.43,0,0,1,6.4,2Z" transform="translate(-.01)"></path>
          </svg>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle Menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>

    

    <div class="initial-content">
      



<div id="main" role="main">
  

  <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
    
    
    
    

    <div class="page__inner-wrap">
      
        <header>
          <!--  -->
          
        </header>
      

      <section class="page__content" itemprop="text">
        
        ```{python}
# HIDDEN
import numpy as np
# %matplotlib inline
import matplotlib.pyplot as plt
plt.style.use('fivethirtyeight')
import pandas as pd
```

```{python}
# HIDDEN

def standard_units(x):
    return (x - np.mean(x))/np.std(x)
```

### Rows of Tables ###

Now that we have a qualitative understanding of nearest neighbor classification, it's time to implement our classifier.

Until this chapter, we have worked mostly with single columns of tables. But now we have to see whether one *individual* is "close" to another. Data for individuals are contained in *rows* of tables.

So let's start by taking a closer look at rows.

Here is the original table `ckd` containing data on patients who were tested for chronic kidney disease.

The data file is [ckd.csv](/dsfe/data/ckd.csv).

```{python}
ckd_full = pd.read_csv('ckd.csv')
ckd_full.head()
```

The data corresponding to the first patient is in row 0 of the table, consistent with Python's indexing system.

We want to fetch the data for this row.

You have already seen how to select rows with boolean arrays, and the `loc` attribute of the data frame.

Now we need to select a row by *index* \- 0, 1, 2 etc.

We do this with Pandas' *indexing* selection, attached to the `iloc` attribute of the data frame, for Indexed LOCate, like this:

```{python}
first_row = ckd_full.iloc[0]
first_row
```

If the display for this row looks suspiciously like the display you see when fetching a single column from a data frame, this is not a co-incidence.  The row is also a Pandas `Series`:

```{python}
type(first_row)
```

Notice that the data type (`dtype`) of the row is `object`, and
not something simpler, like a floating point or integer. This
is because the elements can be of different types, so the
Series needs to use the very general `object` type to store all
the values. For example, some of the elements of the row above
are strings (like `'abnormal'`) and some are numerical. So the
row can't be converted into floating point values or integers.

For example, to access the Albumin level of Patient 0, we can look at the labels in the printout of the row above to find that it's the item at index position 3. We can fetch the value with indexing. Again, we use `iloc`, this time indexing into the `Series`.

```{python}
first_row.iloc[3]
```

### Converting Rows to Numpy arrays  ###

Rows whose elements are all numerical can be converted to numerical Numpy arrays.  Converting a row to a numerical array gives us access to arithmetic operations and other nice NumPy functions, so it is often useful.

Recall that in the previous section we tried to classify the patients as 'CKD' or 'not CKD', based on two attributes `Hemoglobin` and `Glucose`, both measured in standard units.

```{python}
ckd = pd.DataFrame()
ckd['Hemoglobin'] = standard_units(ckd_full['Hemoglobin'])
ckd['Glucose'] = standard_units(ckd_full['Blood Glucose Random'])
ckd['Class'] = ckd_full['Class']
ckd.head()
```

We add the colors for each point, to reflect the Class (with kidney disease or without).

```{python}
ckd['Color'] = 'darkblue'
ckd.loc[ckd['Class'] == 0, 'Color'] = 'gold'
ckd.head()
```

Here is a scatter plot of the two attributes, along with a red point corresponding to Alice, a new patient. Her value of hemoglobin is 0 (that is, at the average) and glucose 1.1 (that is, 1.1 SDs above average).

```{python}
alice = np.array([0, 1.1])
ckd.plot.scatter('Hemoglobin', 'Glucose',
                 c=ckd['Color'])
plt.scatter(alice[0], alice[1], color='red', s=30);
```

To find the distance between Alice's point and any of the other points, we only need the values of the attributes:

```{python}
# Select Hemoglobin and Glucose columns from the data frame
ckd_attributes = ckd[['Hemoglobin', 'Glucose']]
ckd_attributes.head()
```

Each row consists of the coordinates of one point in our training sample. **Because the rows now consist only of numerical values**, it is possible to convert them to numerical arrays.  For this, we use the function `np.array`, which converts any kind of sequential object, like a row, to an array.

```{python}
ckd_attributes.iloc[3]
```

```{python}
np.array(ckd_attributes.iloc[3])
```

This is very handy because we can now use array operations on the data in each row.


### Distance Between Points When There are Two Attributes ###

The main calculation we need to do is to find the distance between Alice's point and any other point. For this, the first thing we need is a way to compute the distance between any pair of points.

How do we do this?  In 2-dimensional space, it's pretty easy.  If we have a point at coordinates $(x_0,y_0)$ and another at $(x_1,y_1)$, the distance between them is

$$
D = \sqrt{(x_0-x_1)^2 + (y_0-y_1)^2}
$$

(Where did this come from?  It comes from the Pythogorean theorem: we have a right triangle with side lengths $x_0-x_1$ and $y_0-y_1$, and we want to find the length of the hypotenuse.)


In the next section we'll see that this formula has a straightforward extension when there are more than two attributes. For now, let's use the formula and array operations to find the distance between Alice and the patient in Row 3.

```{python}
patient3 = np.array(ckd_attributes.iloc[3])
alice, patient3
```

```{python}
distance = np.sqrt(np.sum((alice - patient3)**2))
distance
```

We're going to need the distance between Alice and a bunch of points, so let's write a function called `distance` that computes the distance between any pair of points. The function will take two arrays, each containing the $(x, y)$ coordinates of a point.  (Remember, those are really the Hemoglobin and Glucose levels of a patient.)

```{python}
def distance(point1, point2):
    """Returns the Euclidean distance between point1 and point2.

    Each argument is an array containing the coordinates of a point."""
    return np.sqrt(np.sum((point1 - point2)**2))
```

```{python}
distance(alice, patient3)
```

We have begun to build our classifier: the `distance` function is the first building block. Now let's work on the next piece.


### Using `apply` on an Entire Row ###

Sometimes we want to be able to *apply* some function to a whole row of a data frame.

You won't be surprised to learn that Pandas has an `apply` method that can do this.

Let's see how this works on a very small table `t` containing the information about the first five patients in the training sample.  Here we are using `iloc` again, to get values from the data frame by index.  In this case, we want the first five rows.

```{python}
t = ckd_attributes.iloc[0:5]
t
```

Just as an example, suppose that for each patient we want to know how unusual their most unusual attribute is.  Concretely, if a patient's hemoglobin level is further from the average than her glucose level, we want to know how far it is from the average.  If her glucose level is further from the average than her hemoglobin level, we want to know how far that is from the average instead.

That's the same as taking the maximum of the absolute values of the two quantities. To do this for a particular row, we can convert the row to an array and use array operations.

```{python}
def max_abs(row):
    return np.max(np.abs(np.array(row)))
```

```{python}
max_abs(t.iloc[4])
```

And now we can apply `max_abs` to each row of the table `t`. We pass the `axis` argument to tell Pandas to apply the function along the *rows* (and therefore along the second axis).

```{python}
t.apply(max_abs, axis=1)
```

This way of using `apply` will help us create the next building block of our classifier.


### Alice's $k$ Nearest Neighbors ###

If we want to classify Alice using a k-nearest neighbor classifier, we have to identify her $k$ nearest neighbors. What are the steps in this process? Suppose $k = 5$. Then the steps are:

- **Step 1.** Find the distance between Alice and each point in the training sample.
- **Step 2.** Sort the data table in increasing order of the distances.
- **Step 3.** Take the top 5 rows of the sorted table.

Steps 2 and 3 seem straightforward, provided we have the distances. So let's focus on Step 1.

Here's Alice:

```{python}
alice
```

What we need is a function that finds the distance between Alice and another point whose coordinates are contained in a row. The function `distance` returns the distance between any two points whose coordinates are in arrays. We can use that to define `distance_from_alice`, which takes a row as its argument and returns the distance between that row and Alice.

```{python}
def distance_from_alice(row):
    """Returns distance between Alice and a row of the attributes table"""
    return distance(alice, np.array(row))
```

```{python}
distance_from_alice(ckd_attributes.iloc[3])
```

Now we can `apply` the function `distance_from_alice` to each row of `ckd_attributes`, and augment the table `ckd` with the distances. Step 1 is complete!

```{python}
distances = ckd_attributes.apply(distance_from_alice, axis=1)
ckd_with_distances = ckd.copy()
ckd_with_distances['Distance from Alice'] = distances
ckd_with_distances.head()
```

For Step 2, let's sort the table in increasing order of distance:

```{python}
sorted_by_distance = ckd_with_distances.sort_values('Distance from Alice')
sorted_by_distance.head()
```

Step 3: The top 5 rows correspond to Alice's 5 nearest neighbors; you can replace 5 by any other positive integer.

```{python}
alice_5_nearest_neighbors = sorted_by_distance.iloc[:5]
alice_5_nearest_neighbors
```

Three of Alice's five nearest neighbors are blue points and two are gold. So a 5-nearest neighbor classifier would classify Alice as blue: it would predict that Alice has chronic kidney disease.

The graph below zooms in on Alice and her five nearest neighbors. The two gold ones just inside the circle directly below the red point. The classifier says Alice is more like the three blue ones around her.

```{python}
# NO CODE
plt.figure(figsize=(8,8))
plt.scatter(ckd['Hemoglobin'], ckd['Glucose'],
            c=ckd['Color'], s=40)
plt.scatter(alice[0], alice[1], color='red', s=40)
radius = sorted_by_distance['Distance from Alice'].iloc[4]+0.014
theta = np.arange(0, 2*np.pi+1, 2*np.pi/200)
plt.plot(radius * np.cos(theta) + alice[0],
         radius * np.sin(theta) + alice[1],
         color='g', lw=1.5);
plt.xlim(-2, 2.5)
plt.ylim(-2, 2.5);
```

We are well on our way to implementing our k-nearest neighbor classifier. In the next two sections we will put it together and assess its accuracy.

<div class="isa_info">
<i class="fa fa-info-circle"></i>
This page has content from the
<a href="https://github.com/data-8/textbook/blob/64b20f0/notebooks/Rows_of_Tables.ipynb">
Rows_of_Tables</a>
notebook from the UC Berkeley course.  See the Berkeley course section of the
<a href="/dsfe/license">license</a>
</div>


        
      </section>

      <footer class="page__meta">
        
        


        
      </footer>

      

      

    </div>

    
  </article>

  
  
</div>

    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><input type="text" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
    <div id="results" class="results"></div></div>
      </div>
    

    

    
  <script src="/dsfe/assets/js/main.min.js"></script>
  <script src="https://use.fontawesome.com/releases/v5.0.12/js/all.js"></script>




<script src="/dsfe/assets/js/lunr/lunr.min.js"></script>
<script src="/dsfe/assets/js/lunr/lunr-store.js"></script>
<script src="/dsfe/assets/js/lunr/lunr-en.js"></script>




    <!-- Custom scripts to load after site JS is loaded -->

    <!-- Custom HTML used for the textbooks -->
<!-- Configure, then load MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true,
      processEnvironments: true
    }
  };
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML-full,Safe" type="text/javascript"></script>


<script type="text/javascript">
// --- To auto-embed hub URLs in interact links if given in a RESTful fashion ---
function getJsonFromUrl(url) {
  var query = url.split('?');
  if (query.length < 2) {
    // No queries so just return false
    return false;
  }
  query = query[1];
  // Collect REST params into a dictionary
  var result = {};
  query.split("&").forEach(function(part) {
    var item = part.split("=");
    result[item[0]] = decodeURIComponent(item[1]);
  });
  return result;
}

// Parse a Binder URL, converting it to the string needed for JupyterHub
function binder2Jupyterhub(url) {
  newUrl = {};
  parts = url.split('v2/gh/')[1];
  // Grab the base repo information
  repoinfo = parts.split('?')[0];
  var [org, repo, ref] = repoinfo.split('/');
  newUrl['repo'] = ['https://github.com', org, repo].join('/');
  newUrl['branch'] = ref
  // Grab extra parameters passed
  params = getJsonFromUrl(url);
  if (params['filepath'] !== undefined) {
    newUrl['subPath'] = params['filepath']
  }
  return jQuery.param(newUrl);
}

// Filter out potentially unsafe characters to prevent xss
function safeUrl(url)
{
   return String(encodeURIComponent(url))
            .replace(/&/g, '&amp;')
            .replace(/"/g, '&quot;')
            .replace(/'/g, '&#39;')
            .replace(/</g, '&lt;')
            .replace(/>/g, '&gt;');
}

function addParamToInternalLinks(hub) {
  var links = $("a").each(function() {
    var href = this.href;
    // If the link is an internal link...
    if (href.search("https://matthew-brett.github.io") !== -1 || href.startsWith('/') || href.search("127.0.0.1:") !== -1) {
      // Assume we're an internal link, add the hub param to it
      var params = getJsonFromUrl(href);
      if (params !== false) {
        // We have REST params, so append a new one
        params['hub'] = hub;
      } else {
        // Create the REST params
        params = {'hub': hub};
      }
      // Update the link
      var newHref = href.split('?')[0] + '?' + jQuery.param(params);
      this.setAttribute('href', decodeURIComponent(newHref));
    }
  });
  return false;
}

  // Update interact links
function updateInteractLink() {
    // hack to make this work since it expects a ? in the URL
    rest = getJsonFromUrl("?" + location.search.substr(1));
    hubUrl = rest['hub'];
    if (hubUrl !== undefined) {
      // Sanitize the hubUrl
      hubUrl = safeUrl(hubUrl);
      // Add HTTP text if omitted
      if (hubUrl.indexOf('http') < 0) {hubUrl = 'http://' + hubUrl;}
      link = $("a.interact-button")[0];
      if (link !== undefined) {
          // Update the interact link URL
          var href = link.getAttribute('href');
          if ('binder' == 'binder') {
            // If binder links exist, we need to re-work them for jupyterhub
            first = [hubUrl, 'hub', 'user-redirect', 'git-sync'].join('/')
            href = first + '?' + binder2Jupyterhub(href);
          } else {
            // If JupyterHub links, we only need to replace the hub url
            href = href.replace("https://mybinder.org", hubUrl);
          }
          link.setAttribute('href', decodeURIComponent(href));

          // Add text after interact link saying where we're launching
          hubUrlNoHttp = decodeURIComponent(hubUrl).replace('http://', '').replace('https://', '');
          $("a.interact-button").after($('<div class="interact-context">on ' + hubUrlNoHttp + '</div>'));

      }
      // Update internal links so we retain the hub url
      addParamToInternalLinks(hubUrl);
    }
}

// --- Highlight the part of sidebar for current page ---

// helper to replace trailing slash
function replaceSlash(string)
{
    return string.replace(/\/$/, "");
}

// Add a class to the current page in the sidebar
function highlightSidebarCurrentPage()
{
  var currentpage = location.href;
  var links = $('.sidebar .nav__items a');
  var ii = 0;
  for(ii; ii < links.length; ii++) {
    var link = links[ii];
    if(replaceSlash(link.href) == replaceSlash(currentpage)) {
      // Add CSS for styling
      link.classList.add("current");
      // Scroll to this element
      $('div.sidebar').scrollTop(link.offsetTop - 300);
    }
  }
}

// --- Set up copy/paste for code blocks ---
function addCopyButtonToCode(){
  // get all <code> elements
  var allCodeBlocksElements = $( "div.input_area code, div.highlighter-rouge code" );

  allCodeBlocksElements.each(function(ii) {
   	// add different id for each code block

  	// target
    var currentId = "codeblock" + (ii + 1);
    $(this).attr('id', currentId);

    //trigger
    var clipButton = '<button class="btn copybtn" data-clipboard-target="#' + currentId + '"><img src="https://clipboardjs.com/assets/images/clippy.svg" width="13" alt="Copy to clipboard"></button>';
       $(this).after(clipButton);
    });

    new Clipboard('.btn');
}

// Run scripts when page is loaded
$(document).ready(function () {
  // Add anchors to H1 etc links
  anchors.add();
  // Highlight current page in sidebar
  highlightSidebarCurrentPage();
  // Add copy button to code blocks
  addCopyButtonToCode();
  // Update the Interact link if a REST param given
  updateInteractLink();
});
</script>

  </body>
</html>
